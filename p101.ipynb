{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Orchestration\n",
    "\n",
    "![img](https://miro.medium.com/max/1400/1*VTRH5WAotHAz_yKD-1XqWg.png)\n",
    "\n",
    "Workflow orchestration frameworks are primarily used to coordinate, monitor and observe the movement of data in production applications. \n",
    "\n",
    "Such frameworks typically include a family of independent features that collectively make modern data pipelines fault-tolerant and robust. These features include:\n",
    "\n",
    "* scheduling and triggering jobs\n",
    "* retrying failed work\n",
    "* dependency and state management\n",
    "* caching expensive tasks\n",
    "* resource management\n",
    "* observability\n",
    "\n",
    "These allow us to gracefully handle failure events, including scenarios beyond our control like cloud outages or API failures. Without explicitly tracking states in data pipelines, they become prone to triggering premature jobs, re-running already completed work, or even failing haphazardly. \n",
    "\n",
    "The features workflow orchestration provides are not limited to supporting the scheduled movement of data from a source to a destination. \n",
    "\n",
    "These features are also heavily applied in other domains such as machine learning and parameterized report generation. Presently, workflow orchestration is getting simple enough for hobbyists to adopt for personal projects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflows without orchestration\n",
    "\n",
    "Below we're going to demonstrate a very basic example of what happens when you don't take orchestration into account.\n",
    "\n",
    "If you've ever written code before, this will not be new to you, but it is worth making explicit.\n",
    "\n",
    "The code mimics a simple data pipeline, which makes a call to an API service, augments the data, and then writes the results to our database.\n",
    "\n",
    "The major difference is that the API call that we are making will fail half the time. This is hopefully much more frequently than your API calls will fail in production, but is useful for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def call_unreliable_api():\n",
    "    choices = [{\"data\": 42}, \"failure\"]\n",
    "    res = random.choice(choices)\n",
    "    if res == \"failure\":\n",
    "        raise Exception(\"Our unreliable service failed\")\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "def augment_data(data: dict, msg: str):\n",
    "    data[\"message\"] = msg\n",
    "    return data\n",
    "\n",
    "def write_results_to_database(data: dict):\n",
    "    print(f\"Wrote {data} to database successfully!\")\n",
    "    return \"Success!\"\n",
    "\n",
    "def pipeline(msg: str):\n",
    "    api_result = call_unreliable_api()\n",
    "    augmented_data = augment_data(data=api_result, msg=msg)\n",
    "    write_results_to_database(augmented_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the pipeline a few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(msg=\"Super Special Message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Engineering\n",
    "\n",
    "This is obviously a trivial example, and as engineers, we know to expect these things and to deal with them. BUT, dealing with ways code fails is NOT what we set out to do. We set out to write a data pipeline.\n",
    "\n",
    "The process of writing code that deals with failures, instead of writing code that performs the actions that we want done, is something that we refer to as `Negative Engineering`. \n",
    "\n",
    "> Negative Engineering happens when engineers write defensive code to make sure the positive code acutally runs. Writing code that anticipates the infinite number of possible failures.\n",
    "\n",
    "Prefect aims to eliminate as much of that negative engineering as possible for you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Prefect Flow\n",
    "\n",
    "It's easier to show than it is to tell, so let's run this next block and then we'll explain what is happening.\n",
    "\n",
    "#### Installation \n",
    "First, make sure that `Prefect 2.0` is installed. \n",
    "\n",
    "You can run `pip install -U \"prefect>=2.0b\"` in your command line\n",
    "or you can run `!pip install -U \"prefect>=2.0b\"` in a python cell in your Jupyter Noteook\n",
    "\n",
    "#### Creating a flow\n",
    "To create a flow, we simply import `flow` from `prefect` and then add it as a decorator to our pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from prefect import flow    # NEW **** \n",
    "\n",
    "def call_unreliable_api():\n",
    "    choices = [{\"data\": 42}, \"failure\"]\n",
    "    res = random.choice(choices)\n",
    "    if res == \"failure\":\n",
    "        raise Exception(\"Our unreliable service failed\")\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "def augment_data(data: dict, msg: str):\n",
    "    data[\"message\"] = msg\n",
    "    return data\n",
    "\n",
    "def write_results_to_database(data: dict):\n",
    "    print(f\"Wrote {data} to database successfully!\")\n",
    "    return \"Success!\"\n",
    "\n",
    "@flow   # NEW ****\n",
    "def pipeline(msg: str):\n",
    "    api_result = call_unreliable_api()\n",
    "    augmented_data = augment_data(data=api_result, msg=msg)\n",
    "    write_results_to_database(augmented_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try running our pipeline again a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(\"Trying a flow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our flow still sometimes succeeds and sometimes fails, but something interesting happened. We now have logs, and we see that the error is caught instead of halting execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Prefect Database\n",
    "\n",
    "These logs aren't just printed. These are actually persisted to a database without any effort on your part. This give you visibility into how your code fails or succeeds.\n",
    "\n",
    "By default, the database is a SQLite database that lives at `~/.prefect`.\n",
    "\n",
    "If you execute the `!ls ~/.prefect` command below, you should see `orion.db`.\n",
    "\n",
    "You may or may not also see a `profiles.toml` file. For now ignore it, whether or not you see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit shift + enter to execute command\n",
    "!ls ~/.prefect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the contents of our database\n",
    "\n",
    "I like to use an application called `DB Browser for SQLite` to examine my SQLite databases. You can download it [here](https://sqlitebrowser.org/).\n",
    "\n",
    "We can see the tables that Prefect created in our database below. The table that we care about right now is `log`.\n",
    "\n",
    "<img src=\"images/db1.png\" width=200>\n",
    "\n",
    "If we look at the data in our log table, we can see that our logs were, in fact, saved!\n",
    "\n",
    "<img src=\"images/db2.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making our flows better with tasks\n",
    "\n",
    "Flows are only the first step of orchestrating our data pipelines. The next step is adding Prefect Tasks. \n",
    "\n",
    "A Task can be thought of as a discreet unit of work. If this sounds like a similar description to a function to you, you'd be correct. In practice, you'll often simply convert the functions that make up your flow into tasks.\n",
    "\n",
    "Like Flows, Tasks are created by adding a decorator. We'll demonstrate below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from prefect import flow, task    # NEW **** \n",
    "\n",
    "@task   # NEW ****\n",
    "def call_unreliable_api():\n",
    "    choices = [{\"data\": 42}, \"failure\"]\n",
    "    res = random.choice(choices)\n",
    "    if res == \"failure\":\n",
    "        raise Exception(\"Our unreliable service failed\")\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "@task   # NEW ****\n",
    "def augment_data(data: dict, msg: str):\n",
    "    data[\"message\"] = msg\n",
    "    return data\n",
    "\n",
    "@task   # NEW ****\n",
    "def write_results_to_database(data: dict):\n",
    "    print(f\"Wrote {data} to database successfully!\")\n",
    "    return \"Success!\"\n",
    "\n",
    "@flow \n",
    "def pipeline(msg: str):\n",
    "    api_result = call_unreliable_api()\n",
    "    augmented_data = augment_data(data=api_result, msg=msg)\n",
    "    write_results_to_database(augmented_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our pipeline again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(\"We're using flows and tasks now!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the power of tasks\n",
    "Again, we're still getting errors, but our logs are clearer, and we have better visibility into our data pipeline.\n",
    "\n",
    "### Adding names\n",
    "The first feature of tasks that we're going to show are names. This allows you to add descriptive names to your tasks, independent of the underlying functions name.\n",
    "\n",
    "We do with by passing the `name` parameter to the task decorator. (Note: you can also add names to flow using the `name` parameter)\n",
    "\n",
    "```python\n",
    "@task(name=\"Get data from API\")\n",
    "def call_unreliable_api():\n",
    "```\n",
    "\n",
    "### Adding retries\n",
    "The next feature that we will demo is the ability to retry a task. We know that tasks will inevitably fails. Sometimes this requires complex behavior, but other times we simply need to try again after a brief delay. We can do this with the `retries` and `retry_delay_seconds` parameters.\n",
    "\n",
    "This will be very helpful for our unreliable API call.\n",
    "\n",
    "```python\n",
    "@task(name=\"Get data from API\", retries=4, retry_delay_seconds=2)\n",
    "def call_unreliable_api():\n",
    "```\n",
    "\n",
    "Let's update our code and give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from prefect import flow, task\n",
    "\n",
    "@task(name=\"Get data from API\", retries=4, retry_delay_seconds=2)   # NEW ****\n",
    "def call_unreliable_api():\n",
    "    choices = [{\"data\": 42}, \"failure\"]\n",
    "    res = random.choice(choices)\n",
    "    if res == \"failure\":\n",
    "        raise Exception(\"Our unreliable service failed\")\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "@task(name=\"Add message to data\")   # NEW ****\n",
    "def augment_data(data: dict, msg: str):\n",
    "    data[\"message\"] = msg\n",
    "    return data\n",
    "\n",
    "@task(name=\"Write results to database\")   # NEW ****\n",
    "def write_results_to_database(data: dict):\n",
    "    print(f\"Wrote {data} to database successfully!\")\n",
    "    return \"Success!\"\n",
    "\n",
    "@flow(name=\"Previously unreliable pipeline\")    # NEW ****\n",
    "def pipeline(msg: str):\n",
    "    api_result = call_unreliable_api()\n",
    "    augmented_data = augment_data(data=api_result, msg=msg)\n",
    "    write_results_to_database(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(\"Now we're cooking!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran it a few times, you can see that we still encountered an exception, and that the exception was logged. But this time we were also able to overcome it by retrying, allowing the Flow to complete in the manner we intended. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving on to production-level orchestration\n",
    "\n",
    "So far we have covered trivial examples inside of a Jupyter Notebook. To demonstrate the power of Prefect, we'll need to begin moving outside of the notebook environment. \n",
    "\n",
    "We'll stick with the trivial example for now so that we can focus on concepts, but there will be a more complex flow demonstrated at the end. \n",
    "\n",
    "We've moved the code from the last example to the file `trivial-flow.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployments\n",
    "\n",
    "To perform any of the complex orchestration actions that are coming up, we'll need to create Deployments. These sound a lot more complex than they are.\n",
    "\n",
    "To create a Deployment you need just two things:\n",
    "    * A flow\n",
    "    * A deployment specification\n",
    "\n",
    "We already have a flow, so let's create a deployment specification. The code will be provided below, but it needs to live in a `.py` file. The same code can be found in `trivial-spec.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.deployments import DeploymentSpec, SubprocessFlowRunner\n",
    "\n",
    "DeploymentSpec(\n",
    "    name=\"my-first-deployment\",\n",
    "    flow_location=\"./trivial-flow.py\",\n",
    "    flow_name=\"Previously unreliable pipeline\",\n",
    "    parameters={'msg':'Hello from my first deployment!'},\n",
    "    tags=['ETL'],\n",
    "    flow_runner=SubprocessFlowRunner()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the DeploymentSpec\n",
    "Our flows tell us what we want to do, our deployment specifications tell us how we're going to do it.\n",
    "\n",
    "Specifically, we use the `DeploymentSpec` class to handle specifying the details of how our flow is going to run.\n",
    "\n",
    "#### Understanding the parameters\n",
    "`name` is the name that we our giving our deployment\n",
    "\n",
    "`flow_location` is where the file containing the code that we want to run is located. We can use a relative file path for this.\n",
    "\n",
    "`flow_name` is the name that we provided in our flow decorator\n",
    "\n",
    "`parameters` is the parameters that we want to pass to our flow. If we look back at our flow code, we can see that the function signature is `pipeline(msg: str)`. So we pass a dictionary to our Deployment Spec `{'msg':'Hello from my first deployment!'}` where the key `'msg'` corresponds to our flow's parameter `msg` and the value in the dictonary is the value that we will pass to the flow.\n",
    "\n",
    "`tags` are used to organize deployments. Maybe you have machine learning flows and ETL flows, and you want to quickly be able to separate them. You can tag your machine learning flows with `\"ml\"` and your ETL flows with `\"ETL\"`. Tags are also used for work-queues, which we will explain soon.\n",
    "\n",
    "`flow_runner` specifies the way that you want this flow run. We're going to hand wave this a bit for now so that it's not too distracting. The important thing to know for now is that `SubprocessFlowRunner` is used to run a flow on your local machine.\n",
    "\n",
    "## Breather?\n",
    "\n",
    "That's a lot to cover. All of this will make more sense after we cover the next few several steps, so don't panic if you're feeling fuzzy. Take a moment and then continue forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a deployment\n",
    "\n",
    "Most fun things happen in Prefect using the `prefect` command line tool. The general syntax is `prefect <thing-you-are-dealing-with> <command>`.\n",
    "\n",
    "In our case, we're dealing with deployments, and we want to create one using the deployment specification named `trivial-deployment.py`.\n",
    "\n",
    "We can that by running `prefect deployment create \"trivial-deployment.py\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens when we create a deployment?\n",
    "\n",
    "You should notice that your console printed a few messages. One of them might have been a warning. Ignore that for now. The stuff that we're most interested in is what comes at the end.\n",
    "\n",
    "<img src=\"images/deployment1.png\" width=600>\n",
    "\n",
    "#### Storage\n",
    "When you create a deployment, Prefect saves your code in your storage, and notes its location. Prefect also saves the information from your `DeploymentSpec` in its database. This distinction - that your code goes in YOUR storage - is incredibly important. Prefect is able to orchestrate the execution of your code without ever seeing it, allowing for greater security and privacy.\n",
    "\n",
    "If you navigate to `~/.prefect`, you should see both the database that we have seen already, and storage.\n",
    "\n",
    "<img src=\"images/deployment2.png\" width=400>\n",
    "\n",
    "If we look in the storage directory, we'll see a file with name that is a mix of letters and numbers. \n",
    "\n",
    "<img src=\"images/deployment3.png\" width=200>\n",
    "\n",
    "This is the file that contains our flow code. If we use the `cat` command to examine it, we'll see a copy of our code in the state that it was when we created our deployment.\n",
    "\n",
    "<img src=\"images/deployment4.png\" width=400>\n",
    "\n",
    "Because we've made a copy, if we modify our code in our `trivial-flow.py` file, it will not change the code that the deployment runs until we create a new deployment. This keeps our deployments stable while we continue to develop our flows.\n",
    "\n",
    "#### The Deployment database table\n",
    "While our code is saved to storage, information about deployment is saved to our database. Using the database explorer, we can examine the `deployment` table, where we will see the deployment that we just created.\n",
    "\n",
    "<img src=\"images/deployment5.png\" width=700>\n",
    "\n",
    "You can see that all of our information is there - the name, the tags, the paramters, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Prefect UI\n",
    "\n",
    "We now have flows and deployments. It's time to introduce the Prefect UI. This will allow us to visually inspect our flows and deployments, schedule them, and handle a variety of other important tasks. Right now it will have limited functionality, but in only a few more steps, we'll have access to its full capabilities.\n",
    "\n",
    "To access the UI, type the command `prefect orion start` in your terminal. This will launch a long-running Prefect application. You should see `Check out the dashboard at http://127.0.0.1:4200`. If you scroll up in your terminal a bit, your output should look similar to the picture below:\n",
    "\n",
    "<img src=\"images/ui1.png\" width=300>\n",
    "\n",
    "Click on the link or paste the URL into your web browser to the see the Prefect UI. You should now be able to see the UI, including red and green bars showing failed and succeeded runs, and our flows. \n",
    "\n",
    "<img src=\"images/ui2.png\" width=500>\n",
    "\n",
    "The UI is able to show us the information that Prefect has been saving to our database. If you click around, you will also find the logs for individual flows and tasks. Take a moment and explore.\n",
    "\n",
    "#### Why are my deployments at 0?\n",
    "You may notice that our `Deployments` tab shows `0` even though we just showed that our deployment table in our database has our deployment information. This is because we haven't run any deployments yet. If instead you \n",
    "* 1. click on the `Flows` tab, and then \n",
    "* 2. click on `Previously unreliable pipeline` flow, you will \n",
    "* 3. see `my-first-deployment` under the `Deployments` heading in the sidebar. \n",
    "\n",
    "<img src=\"images/ui3.png\" width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work queues\n",
    "\n",
    "Work queues are one of the last two pieces that we need to begin full orchestration of our flows.\n",
    "\n",
    "Remember tags from our DeploymentSpec? The examples that we used were `ml` for machine learning and `ETL` for, well, ETLs.\n",
    "\n",
    "Work queues are ways for us to organize flows that we want to run, based on things like tags. You can think of it as a fancy filter if you'd like.\n",
    "\n",
    "To create a work queue we use the command `prefect work-queue create -t <tag> <queue-name>` where `<queue-name>` is the name that you want to give the work-queue. When you run the command the console will output will be the work queue's unique ID. \n",
    "\n",
    "Open a new console (because your other console is running the Prefect application) and run the command `prefect work-queue create -t \"ETL\" etl-queue`. Your output should look similar to the image below:\n",
    "\n",
    "<img src=\"images/workq1.png\" width=400>\n",
    "\n",
    "If we check the `work_queue` table of our database we will see `etl-queue` there.\n",
    "\n",
    "<img src=\"images/workq2.png\" width=500>\n",
    "\n",
    "If you ever forget which work queues you have available, you can run the command `prefect work-queue ls` to view them\n",
    "\n",
    "<img src=\"images/workq5.png\" width=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding flow runs to work queues\n",
    "\n",
    "Return to the Prefect UI, click on the `Flows` tab, and then click on the flow `Previously unreliable pipeline`, you will open the sidebar. Once the sidebar is open, look for the `Deployments` heading. To the right you will see the `Quick Run` button. Go ahead and click it. You should briefly see a pop-up that says \"Flow Run Scheduled\".\n",
    "\n",
    "<img src=\"images/workq3.png\" width=500>\n",
    "\n",
    "Your run history should now have a new addition - a yellow bar. If you hover over it, you will see that it says `Late flow runs`. This is because we clicked `Quick Run`, which schedule a flow to be run immediately, but the flow has not started running.\n",
    "\n",
    "<img src=\"images/workq4.png\" width=500>\n",
    "\n",
    "We can check the flows in our work queue by running the command `prefect work-queue preview <work-queue's unique ID>`\n",
    "\n",
    "<img src=\"images/workq6.png\" width=500>\n",
    "\n",
    "So we definitely have a flow lined up in our work queue, but it is late. What's wrong now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents - the final piece of the puzzle!\n",
    "\n",
    "We mentioned elsewhere that your code stays with your infrastructure. This means that the Prefect application never has direct access to it, so it can't run your code for you. All it can do is say which code need to be run, and pass information for your DeploymentSpec. This is the Prefect Hybrid Execution model. You supply the code, we supply the orchestration.\n",
    "\n",
    "In order to start a flow on your computer from the application, we need a Prefect Agent.\n",
    "\n",
    "An Agent is just a long running process that lives on your compute infrastructure. When we create the agent, we provide it a work-queue to monitor. It then queries the Prefect application every 5 seconds, checking if there is code that it should run. When a flow is added to the work-queue that the agent is responsible for, the API sends the agent the flow information. The agent then kicks of the Flow.\n",
    "\n",
    "#### Starting an agent\n",
    "You'll want to open up a new terminal window, because the agent is a long-running process. Then run the magic command `prefect agent start <work-queue-id>`. If you've forgotten your work-queue's unique ID, you can check with `prefect work-queue ls`.\n",
    "\n",
    "<img src=\"images/agent1.png\" width=400>\n",
    "\n",
    "Your agent will immediately begin executing the flow that is in your etl-queue. If you check your work queue again using `prefect work-queue preview <work-queue-id>` you will see that it is empty.\n",
    "\n",
    "<img src=\"images/agent2.png\" width=500>\n",
    "\n",
    "If you check your Run History in the UI again, you will now see that the bar that was previously yellow is now green.\n",
    "\n",
    "<img src=\"images/agent3.png\" width=500>\n",
    "\n",
    "Now if you click `Quick Run` again, the flow will immediately execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Congratulations! You now have all of the basic components needed to orchestrate flows with Prefect. \n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06e6f1dd4f17d3660aa7db23f6d2ce3316c4713bf412bd57fdef93ef3a7eba73"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
